# 《大数据系统基础》实验报告：中科大校内文件搜索引擎

## 1. 小组成员名单与具体分工

| 姓名 | 学号 | 分工 |
| :--- | :--- | :--- |
| [姓名A] | [学号A] | **组长**：项目架构设计、HBase集群环境搭建、分布式爬虫开发、代码仓库管理。 |
| [姓名B] | [学号B] | **算法架构**：搜索引擎核心实现（倒排索引、BM25/TF-IDF算法）、存储层接口封装（HBase/Local Fallback）。 |
| [姓名C] | [学号C] | **全栈开发**：Flask Web后端、响应式前端界面、测试数据处理、项目文档与实验报告撰写。 |

---

## 2. 技术路线

本项目旨在构建一个针对中科大校内网站的分布式文件搜索引擎。主要技术栈如下：

### 2.1 数据采集：Scrapy 爬虫框架
利用 **Scrapy** 的异步处理能力实现高性能爬虫。
- **广度优先搜索 (BFS)**：遍历中科大各二级学院站点。
- **智能过滤**：专门针对“下载中心”等路径进行深度优先抓取。
- **内容提取**：使用 `PyPDF2`、`python-docx` 等库解析非结构化文件（PDF/DOCX）。

### 2.2 数据存储：HBase 分布式数据库 (本课程核心)
使用 **HBase** 作为底层海量数据存储引擎。
- **Row Key 设计**：采用 `MD5(URL)[:8] + Timestamp`，既保证了 Row Key 的均匀分布（防止写热点），又支持记录的快速定位。
- **列族设计**：
    - `info`: 存储文档元数据（URL、标题、纯文本内容、抓取时间）。
    - `index`: 存储预构建的倒排索引信息。
- **Fallback 机制**：针对开发环境的不确定性，实现了 HBase 到本地文件存储的平滑切换，提升了系统的健壮性。

### 2.3 搜索引擎核心：自建倒排索引与相关度排序
放弃现成的 Elasticsearch，选择从底层实现搜索引擎，以深入理解大数据搜索原理。
- **分词引擎**：基于 `jieba` 中文分词，并添加科大校内专有名词词典（如“中国科学技术大学”、“教务处”等）。
- **相关度计算算法 (Ranking)**：
    - **BM25 算法 (默认)**：相比于传统的 TF-IDF，BM25 引入了两个关键参数 $k_1$（词频饱和度）和 $b$（文档长度归一化）。
        - **词频饱和**：当一个词在文档中出现的次数增加到一定程度后，其对分数的贡献趋于平缓，避免了长文档因词频堆积而获得过高分数。
        - **长度归一化**：惩罚过长的文档，奖励包含查询词的短文档。
        - **公式**：
          $$ Score(D, Q) = \sum_{i=1}^{n} IDF(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{avgdl})} $$
          其中 $f(q_i, D)$ 是词 $q_i$ 在文档 $D$ 中的频率，$|D|$ 是文档长度，$avgdl$ 是平均文档长度。本项目设定 $k_1=1.5, b=0.75$。
    - **标题加权 (Title Weight)**：
        - 在基础相关度分数之上，系统会对文档标题进行二次匹配。
        - 如果查询词在标题中出现的比例超过 80%，最终分数 $\times 2.0$。
        - 如果比例超过 50%，最终分数 $\times 1.5$。
        - **设计意图**：用户通常更倾向于点击标题中直接包含查询关键词的文档。
- **倒排索引构建**：
    - 遍历所有文档，建立 `Token -> [DocID1, DocID2, ...]` 的映射。
    - 搜索时，先通过倒排索引快速召回候选文档集合，再对候选集计算 BM25 分数并排序，最后返回 Top-N 结果。

### 2.4 用户界面：Flask + Bootstrap
- **Flask**：轻量级 Web 服务器，负责解析搜索请求并调用 HBase 数据。
- **响应式 UI**：基于 Bootstrap 开发，适配 PC 和移动端。

---

## 3. 实现功能介绍与效果展示

### 3.1 核心功能
1. **深度爬取**：能够穿透到“下载中心”等三级目录抓取文件。
2. **多源搜索**：支持按站点来源（如 `finance.ustc.edu.cn`）进行精准筛选。
3. **毫秒级查询**：基于倒排索引和 HBase 的高效读取，在数万条数据中实现快速响应。

### 3.2 效果展示
*(此处可插入截图：1. 搜索“财务”返回的表格结果；2. 搜索“招生”返回的 PDF 下载链接；3. 手机端访问的界面)*

---

## 4. 核心代码块

### 4.1 HBase 数据写入接口 (`storage/hbase_client.py`)
展示如何将爬取到的非结构化文档持久化到分布式表中。

```python
def _save_to_hbase(self, doc: Document, row_key: str) -> str:
    try:
        table = self.connection.table(self.table_name)
        data = doc.to_dict()
        # 准备HBase数据，存储在 info 列族下
        hbase_data = {}
        for key, value in data.items():
            if value:
                hbase_data[f'info:{key}'] = str(value).encode('utf-8')
        
        table.put(row_key.encode(), hbase_data)
        return row_key
    except Exception as e:
        print(f"Error saving to HBase: {e}")
        raise
```

### 4.2 BM25 排序算法与标题加权 (`search/ranking.py`, `search/searcher.py`)
体现系统对搜索质量的控制逻辑：结合了概率模型 BM25 与规则模型（标题加权）。

```python
# search/ranking.py: BM25 核心计算
def calculate_bm25(self, doc_tokens: List[str], query_tokens: List[str]) -> float:
    score = 0.0
    doc_length = len(doc_tokens)
    doc_token_freq = Counter(doc_tokens)
    
    for query_token in query_tokens:
        if query_token in doc_token_freq:
            tf = doc_token_freq[query_token]
            # IDF * (TF部分)
            numerator = self.idf_cache.get(query_token, 0) * tf * (self.k1 + 1)
            denominator = tf + self.k1 * (1 - self.b + self.b * (doc_length / max(self.avg_doc_length, 1)))
            score += numerator / max(denominator, 1)
    return score

# search/searcher.py: 综合评分逻辑
# ...
# 1. 计算基础 BM25 分数
score = ranker.calculate_bm25(tokens, query_tokens)

# 2. 应用标题权重 (Title Weight)
title_tokens = self.tokenizer.tokenize_title(doc.title)
title_weight = calculate_title_weight(title_tokens, query_tokens) # 匹配度高则返回 1.5 或 2.0
score *= title_weight
# ...
```

---

## 5. 同学总结与心得

### [姓名A] 的总结
**踩坑总结**：最初在 Linux 上部署时，发现 HBase 的 Thrift 接口默认未启动，导致 Python 始终连接失败。通过排查日志才发现需要手动启动 `hbase-daemon.sh start thrift`。
**实验收获**：深刻理解了 HBase 列式存储的优势，尤其是在存储长短不一、结构多变的网页正文时，比传统关系型数据库更灵活。

### [姓名B] 的总结
**错误总结**：在构建倒排索引时，最初没有做 URL 去重，导致搜索结果中出现了大量重复内容。后来引入了 `SimHash` 算法进行指纹对比，有效解决了内容冗余问题。
**实验心得**：手动实现搜索引擎比调用 API 难得多，但让我彻底搞清楚了 TF-IDF 到 BM25 的演进逻辑，对信息检索有了全新的认识。

### [姓名C] 的总结
**心得感悟**：大数据系统不仅是存储，更是数据的“清洗与组织”。在处理 PDF 文本提取时，遇到了很多乱码问题，通过引入 `pdfminer.six` 并配合正则表达式清洗，才得到了高质量的索引文本。
**收获**：学会了如何在无 root 权限的服务器上通过二进制包部署整套大数据组件，极大地锻炼了 Linux 运维能力。


