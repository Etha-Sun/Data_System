# 演示文档：中科大校内文件搜索引擎

## 🚀 项目概览
- **核心目标**：实现对 USTC 各院系网站文件的分布式抓取、存储与检索。
- **底层架构**：Scrapy + HBase + Flask。
- **当前状态**：✅ HBase 服务运行中，✅ 54+ 条核心数据已入库。

---

## 🛠️ 第一步：环境检查
演示前确保所有基础组件正常工作：

1. **HBase 状态**：
   ```bash
   ps aux | grep hbase
   ```
   *预期：应能看到 HMaster 和 ThriftServer 进程。*

2. **Web 服务**：
   访问 `http://localhost:5000`

---

## 🔍 第二步：功能演示流程

### 1. 关键词搜索
在搜索框中输入以下关键词展示搜索能力：
- **“财务”**：展示针对财务处下载中心的抓取结果。
- **“中科大”**：展示通用新闻和门户页面的匹配。
- **“人工智能”**：展示对近期热点新闻（如人工智能研究院）的抓取。

### 2. 来源筛选
- 点击“来源网站”下拉框。
- 选择 `finance.ustc.edu.cn`。
- **效果**：结果将仅展示来自财务处的通知与文件。

### 3. 文档属性与相关度展示
展示结果卡片中的详细信息，解释为什么这个结果排在前面：
- **相关性分数 (Score)**：展示 BM25 算法计算出的得分（如 `Score: 8.42`）。
    - 解释：这是一个基于概率统计的分数，分数越高表示文档与查询词越相关。
- **标题加权**：如果搜索词完整出现在标题中，强调该结果获得了 2.0 倍的权重加成。
- **文件摘要**：展示系统自动生成的文本片段，关键词高亮。

---

## 📊 第三步：后台数据演示
向观众展示数据是如何存储在 HBase 中的：

1. **查看 HBase 数据总量**：
   ```bash
   source venv/bin/activate
   python -c "from storage.hbase_client import HBaseClient; print(len(HBaseClient().get_all_documents()))"
   ```

2. **HBase Shell 直接查询**：
   ```bash
   ./hbase/bin/hbase shell
   scan 'ustc_documents', {LIMIT => 1}
   ```
   *展示 Row Key 设计及 info 列族中的二进制内容。*

---

## 📈 第四步：爬虫实时抓取演示
展示系统具有持续增长数据的能力：

1. **查看爬虫日志**：
   ```bash
   tail -f crawler.log
   ```
   *展示爬虫正在实时解析 URL 并将 Items 发送到 HBase Pipeline。*

---

## 💡 技术 Q&A 准备
- **Q**: 为什么不用 ES？
- **A**: 为了深入学习大数据底层存储和搜索引擎算法，我们选择了 HBase 作为存储引擎并手写了倒排索引。
- **Q**: 搜索结果是如何排序的？
- **A**: 我们使用了工业界标准的 **BM25 算法**，相比 TF-IDF，它能更好地处理长文档和词频饱和问题。此外，我们还加入了**标题加权策略**，让标题中包含关键词的文档优先展示，更符合用户搜索习惯。
- **Q**: 遇到最大的挑战是什么？
- **A**: 在无 sudo 权限的环境下部署 HBase 以及 PDF 文档的复杂文本提取。


